{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795336c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv2d_7\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_7/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_7/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n\nCall arguments received by layer \"conv2d_7\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 148\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     28\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(images), np\u001b[38;5;241m.\u001b[39marray(labels), test_size\u001b[38;5;241m=\u001b[39mTEST_SIZE\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Get a compiled neural network\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Fit model on training data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 140\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model\u001b[39m():\n\u001b[1;32m    104\u001b[0m     layers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;66;03m# tf.keras.layers.Conv2D(\u001b[39;00m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;66;03m#     128, (3, 3), activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m     ]\n\u001b[0;32m--> 140\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    142\u001b[0m                   loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    143\u001b[0m                   metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1967\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1964\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1966\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 1967\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1970\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_7\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_7/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_7/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n\nCall arguments received by layer \"conv2d_7\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "EPOCHS = 10\n",
    "IMG_WIDTH = 30\n",
    "IMG_HEIGHT = 30\n",
    "TUMOR_CLASSES = [\"category1_tumor\", \"category2_tumor\", \"category3_tumor\", \"no_tumor\"]\n",
    "TEST_SIZE = 0.4\n",
    "DIRECTORY = \"../Datathon-Dataset\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Seed for reproducibility\n",
    "    tf.random.set_seed(123)\n",
    "\n",
    "    # Get image arrays and labels for all image files\n",
    "    images, labels = load_data(DIRECTORY)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    labels = tf.keras.utils.to_categorical(labels)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        np.array(images), np.array(labels), test_size=TEST_SIZE\n",
    "    )\n",
    "\n",
    "    # Get a compiled neural network\n",
    "    model = get_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=2,restore_best_weights=True, verbose=2)\n",
    "    # Fit model on training data\n",
    "    start_time = time.time()\n",
    "    history = model.fit(x_train, y_train, epochs=EPOCHS, callbacks=[early_stopping], validation_split=0.2,\n",
    "                        validation_data=(x_test, y_test), verbose=2)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Evaluate neural network performance\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "    predictions = model.predict(x_test)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    print(\"Time taken: \", end_time - start_time, \" seconds\")\n",
    "    print(f\"\\nLoss: {loss}\")\n",
    "    print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"Recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"Precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"F1 Score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    with open('logs.txt', 'a') as f:\n",
    "        #write model summary and evaluation metrics to file\n",
    "        f.write(\"\\n\\n\\nModel Summary: \\n\")\n",
    "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "        f.write(\"\\nTime taken: \" + str(end_time - start_time) + \" seconds\" )\n",
    "        f.write(\"\\nLoss: \" + str(loss))\n",
    "        f.write(\"\\nAccuracy: \" + str(accuracy))\n",
    "        f.write(\"\\nRecall: \" + str(recall_score(y_test, y_pred, average='weighted')))\n",
    "        f.write(\"\\nPrecision: \" + str(precision_score(y_test, y_pred, average='weighted')))\n",
    "        f.write(\"\\nF1 Score: \" + str(f1_score(y_test, y_pred, average='weighted')))\n",
    "        f.write(\"_________________________________________________________________\")\n",
    "\n",
    "\n",
    "    # plot the training and validation accuracy and loss at each epoch and add a title and axis labels and legend\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(train_loss))\n",
    "    plt.plot(epochs, train_loss, 'r', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Save model to file\n",
    "    if len(sys.argv) == 2:\n",
    "        filename = sys.argv[1]\n",
    "        model.save(filename)\n",
    "        print(f\"Model saved to {filename}.\")\n",
    "\n",
    "\n",
    "def load_data(base_path):\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for i, tumor_class in enumerate(TUMOR_CLASSES):\n",
    "        class_path = os.path.join(base_path, tumor_class)\n",
    "\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                img = cv2.imread(os.path.join(class_path, filename))\n",
    "                img = enhance_image(img)\n",
    "                img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                images.append(img)\n",
    "                labels.append(i)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def enhance_image(img):\n",
    "    img = Image.fromarray(np.uint8(img))\n",
    "    img = ImageEnhance.Brightness(img).enhance(1.5)\n",
    "    img = ImageEnhance.Contrast(img).enhance(1.5)\n",
    "    img = ImageEnhance.Sharpness(img).enhance(1.5)\n",
    "    img = np.array(img) / 255.0\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(\n",
    "            128, (3, 3), activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3),padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\",padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\",padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\",padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\",padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
    "\n",
    "        # Flatten units\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        # Add hidden layers with dropout\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        # Output layer\n",
    "        tf.keras.layers.Dense(4, activation=\"softmax\"),\n",
    "\n",
    "    ]\n",
    "\n",
    "    model = tf.keras.models.Sequential(layers)\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6aa9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
